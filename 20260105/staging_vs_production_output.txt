[WARN] pyarrow is not installed by default since databricks-sql-connector 4.0.0,any arrow specific api (e.g. fetchmany_arrow) and cloud fetch will be disabled.If you need these features, please run pip install pyarrow or pip install databricks-sql-connector[pyarrow] to install

================================================================================
STAGING vs PRODUCTION COMPARISON
================================================================================

Purpose: Prove that Census sync wrote updated data to Product_Property__c
         that differs from what exists in Property__c (production)

→ Loading staging data (Product_Property__c)...
✓ Loaded 200 records from staging

→ Connecting to Databricks to fetch production data...
→ Querying production Property__c for 200 properties...
Error in sys.excepthook:
Traceback (most recent call last):
  File "/opt/homebrew/lib/python3.14/site-packages/databricks/sql/telemetry/telemetry_client.py", line 546, in _handle_unhandled_exception
    client.close()
    ^^^^^^^^^^^^
AttributeError: '_TelemetryClientHolder' object has no attribute 'close'

Original exception was:
Traceback (most recent call last):
  File "/Users/danerosa/rds_databricks_claude/20260105/compare_staging_vs_production.py", line 285, in <module>
    main()
    ~~~~^^
  File "/Users/danerosa/rds_databricks_claude/20260105/compare_staging_vs_production.py", line 277, in main
    production_data = query_production_salesforce(property_ids)
  File "/Users/danerosa/rds_databricks_claude/20260105/compare_staging_vs_production.py", line 79, in query_production_salesforce
    cursor.execute(query)
    ~~~~~~~~~~~~~~^^^^^^^
  File "/opt/homebrew/lib/python3.14/site-packages/databricks/sql/telemetry/latency_logger.py", line 182, in wrapper
    return func(self, *args, **kwargs)
  File "/opt/homebrew/lib/python3.14/site-packages/databricks/sql/client.py", line 1319, in execute
    self.active_result_set = self.backend.execute_command(
                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        operation=prepared_operation,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<9 lines>...
        row_limit=self.row_limit,
        ^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/opt/homebrew/lib/python3.14/site-packages/databricks/sql/backend/thrift_backend.py", line 1054, in execute_command
    execute_response, has_more_rows = self._handle_execute_response(
                                      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        resp, cursor
        ^^^^^^^^^^^^
    )
    ^
  File "/opt/homebrew/lib/python3.14/site-packages/databricks/sql/backend/thrift_backend.py", line 1261, in _handle_execute_response
    final_operation_state = self._wait_until_command_done(
        resp.operationHandle,
        resp.directResults and resp.directResults.operationStatus,
    )
  File "/opt/homebrew/lib/python3.14/site-packages/databricks/sql/backend/thrift_backend.py", line 940, in _wait_until_command_done
    self._check_command_not_in_error_or_closed_state(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        op_handle, initial_operation_status_resp
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/opt/homebrew/lib/python3.14/site-packages/databricks/sql/backend/thrift_backend.py", line 633, in _check_command_not_in_error_or_closed_state
    raise ServerOperationError(
    ...<7 lines>...
    )
databricks.sql.exc.ServerOperationError: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `idv_enabled` cannot be resolved. Did you mean one of the following? [`name`, `is_deleted`, `lead_c`, `fka_c`, `id`]. SQLSTATE: 42703; line 4 pos 8
